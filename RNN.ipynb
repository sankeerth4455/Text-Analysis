{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWbyrUcAsOrP"
      },
      "source": [
        "# Lab 6: Recurrent neural networks\n",
        "\n",
        "In this lab you will use a recurrent neural network to predict whether or not a *tweet* is talking about a real disaster or not. To do this, we will use *Kaggle.com*'s competition [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started). Please follow the competition directions to obtain the data and evaluate your final model, noting the extra requirements below. **There is no requirement to actually submit your resutls to the competition.**\n",
        "\n",
        "**Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.**\n",
        "\n",
        "**Requirements**\n",
        " - Keras's `TextVectorization` functionality must be used, although it need not be part of the model\n",
        " - `train.csv` should be split into training and validation sets\n",
        " - the heart of your model must only use recurrent layers chosen from those [available in Keras](https://keras.io/api/layers/#recurrent-layers)\n",
        " - an embedding layer should be used; this can be learned along with the main task or use the [GloVe](https://github.com/stanfordnlp/GloVe) or [word2vec]() pretrained word embeddings\n",
        " - the evaluation metric for this dataset is the [F1-Score](https://www.kaggle.com/c/nlp-getting-started/overview/evaluation)\n",
        "\n",
        "**Grading:**\n",
        "\n",
        " - 50% of the grade will come from FINAL, error-free code written in Python/Keras that accomplishes all the steps outlined  \n",
        " - 50% will come from descriptive comments associated with that code, where the comments explain what the code is doing and why it is important to the overall objective; see example below\n",
        "\n",
        "```\n",
        "def one_hot_encode_token(token):\n",
        "    \"\"\"This function can be used to convert integer encoded vectors to one-hot-encoded vectors.\n",
        "    It processes one integer at a time and requires that vocabulary indexing already be done.\n",
        "    input:\n",
        "        token: an integer, e.g., 3\n",
        "    return:\n",
        "        vector: a one-hot vector of vocabulary length, [0, 0, 0, 1, 0,...]\n",
        "    \"\"\"\n",
        "    vector = np.zeros((len(vocabulary),))\n",
        "    vector[token] = 1\n",
        "    return vector\n",
        "```\n",
        "\n",
        "\n",
        "**What to submit:**\n",
        "- a copy of this notebook with:\n",
        "    - final, well-commented, error-free code in Python/Keras\n",
        "    - all code cells executed and output visible\n",
        "- a `submission.csv` file containing the predictions of your final model on the `test.csv` data\n",
        "- the final version of your model saved as a `Group_#_Lab_6.keras` file\n",
        "\n",
        "**What NOT to submit:**\n",
        " - data files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kCexHdtsOrS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjkbT_eJsOrT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./data/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oljg7LhHsOrU",
        "outputId": "73f9084b-379a-483c-fbbd-c361a8713435"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNc9lNnsOrU"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa7DEZdLsOrV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\"\"\"USING REGULAR EXPRESSION PATTERNS, WE WILL CLEAN THE TWEET DATA\"\"\"\n",
        "\n",
        "\"\"\" THIS METHOD REMOVES URL IN THE A SENTENCE \"\"\"\n",
        "def remove_url(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)\n",
        "\n",
        "\"\"\" THIS METHOD REMOVES USER MENTIONS STARTING WITH @\"\"\"\n",
        "def remove_mentions(text):\n",
        "    url = re.compile(r'@[A-Za-z0-9]+')\n",
        "    return url.sub(r'',text)\n",
        "\n",
        "\"\"\" THISI METHOD REMOVES PUNCTUATIONS\"\"\"\n",
        "def remove_punct(text):\n",
        "    table=str.maketrans('','',string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "\"\"\" THISI METHOD REMOVES ANY HTML TAGS IN THE SENTENCES\"\"\"\n",
        "def remove_html(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "\n",
        "\"\"\" REMOVES ALPHANUMERIC WORDS \"\"\"\n",
        "def remove_alphanumeric(text):\n",
        "    html=re.compile(r'\\w*\\d\\w*')\n",
        "    return html.sub(r'',text)\n",
        "\n",
        "\"\"\" REMOVES NEW LINES\"\"\"\n",
        "def remove_newline(text):\n",
        "    html=re.compile(r'\\n')\n",
        "    return html.sub(r' ',text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYUw6cTgsOrV"
      },
      "outputs": [],
      "source": [
        "\"\"\"DEFINING A METHOD THAT WILL \"\"\"\n",
        "def clean(df):\n",
        "    \"\"\"\n",
        "    input:\n",
        "          a dataframe with a text column containing tweets\n",
        "    return:\n",
        "          the same data frame after cleaning the tweet column\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\" CONVERTING ALL TO LOWERCASE\"\"\"\n",
        "    df['text']=df['text'].apply(lambda x : x.lower())\n",
        "\n",
        "    \"\"\" REMOVING URLS \"\"\"\n",
        "    df['text']=df['text'].apply(lambda x : remove_url(x))\n",
        "\n",
        "    \"\"\" REMOVING MENTIONS @\"\"\"\n",
        "    df['text']=df['text'].apply(lambda x : remove_mentions(x))\n",
        "\n",
        "    \"\"\" REMOVING PUNCTUATIONS\"\"\"\n",
        "    df['text']=df['text'].apply(lambda x : remove_punct(x))\n",
        "\n",
        "    \"\"\" REMOVING HTML\"\"\"\n",
        "    df['text']=df['text'].apply(lambda x : remove_html(x))\n",
        "\n",
        "    \"\"\" REMOVING ALPHANUMERIC WORDS\"\"\"\n",
        "    df['text']=df['text'].apply(lambda x : remove_alphanumeric(x))\n",
        "\n",
        "    df['text']=df['text'].apply(lambda x : remove_newline(x))\n",
        "\n",
        "    return df\n",
        "\n",
        "df_clean = clean(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXVaOVyCsOrV",
        "outputId": "c42c7bec-34b4-4e89-803f-34977b28a058"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>people receive wildfires evacuation orders in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  our deeds are the reason of this earthquake ma...       1\n",
              "1              forest fire near la ronge sask canada       1\n",
              "2  all residents asked to shelter in place are be...       1\n",
              "3   people receive wildfires evacuation orders in...       1\n",
              "4  just got sent this photo from ruby alaska as s...       1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dropping unwanted columns\n",
        "df_clean= df_clean.drop(['id', 'keyword', 'location'], axis = 1)\n",
        "\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCZa0eeZsOrV"
      },
      "source": [
        "### PERFORMING VECTORIZATION AND PADDING (USING KERAS VECTORIZATION LAYER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKzRao64sOrW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf_data = tf.data.Dataset.from_tensor_slices(df_clean['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzcAJP_HsOrW"
      },
      "outputs": [],
      "source": [
        "#initializing keras text vectorization layer with output mode as count\n",
        "\n",
        "text_vectorization = tf.keras.layers.TextVectorization(output_mode='int',\n",
        "    max_tokens=None, standardize='lower_and_strip_punctuation',\n",
        "    split='whitespace', ngrams=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ehIs_5KsOrW"
      },
      "outputs": [],
      "source": [
        "#calling the adapt method on the layer to learn the vocabulary from the input text\n",
        "text_vectorization.adapt(tf_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEei7aB8sOrW",
        "outputId": "4dbc3f6d-79c7-470c-b59d-86af8ae97bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72136\n"
          ]
        }
      ],
      "source": [
        "vocab_length = len(text_vectorization.get_vocabulary())\n",
        "print(vocab_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLpdJ6O_sOrX"
      },
      "outputs": [],
      "source": [
        "#coverting the text data to vectors containing integers using the adapted layer\n",
        "text_vectorized = text_vectorization(df_clean['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6DBrDRCsOrX"
      },
      "outputs": [],
      "source": [
        "#padding the vectorized data so that all the samples are of the same length before passing to the model\n",
        "text_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    text_vectorized, maxlen=None, dtype='int32', padding='post',\n",
        "    truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRG3UfM8sOrX",
        "outputId": "6f25483d-b4a9-42df-d058-332e4579f26a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7613, 61)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_padded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoTcwmoasOrX"
      },
      "outputs": [],
      "source": [
        "max_length = text_padded.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsX-bRTVsOrX"
      },
      "source": [
        "### CREATE AND EVALUATE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyILKiOOsOrX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(text_padded, df_clean['target'],test_size= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQuL-rrrsOrY"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\"\"\"\n",
        "Defining methods to calculate Recall, Precision and F1 scores\n",
        "\n",
        "These are callback methods which will be executed in the fit method, in addition to the regular accuracy\n",
        "\"\"\"\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5_edrHgsOrY",
        "outputId": "30af280d-6069-4b9f-91aa-fb25ac7793cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 61, 8)             577088    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 61, 32)            5248      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1952)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1953      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 584,289\n",
            "Trainable params: 584,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim =  vocab_length, output_dim = 8, input_length=max_length))\n",
        "model.add(LSTM(32,activation='relu',return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc',f1])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni5zMnQosOrY",
        "outputId": "a86fdf5f-79b4-4e09-d542-b3f074576562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "191/191 [==============================] - 8s 31ms/step - loss: 0.7862 - acc: 0.6388 - f1: 0.2853 - val_loss: 0.5436 - val_acc: 0.7630 - val_f1: 0.7118\n",
            "Epoch 2/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.3553 - acc: 0.8650 - f1: 0.8390 - val_loss: 0.4916 - val_acc: 0.7722 - val_f1: 0.728646 - f1 - ETA: 0s - loss: 0.3598 - acc:\n",
            "Epoch 3/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.2057 - acc: 0.9386 - f1: 0.9207 - val_loss: 0.5107 - val_acc: 0.7695 - val_f1: 0.7313\n",
            "Epoch 4/10\n",
            "191/191 [==============================] - 6s 31ms/step - loss: 0.0945 - acc: 0.9727 - f1: 0.9671 - val_loss: 0.5592 - val_acc: 0.7676 - val_f1: 0.7290\n",
            "Epoch 5/10\n",
            "191/191 [==============================] - 6s 31ms/step - loss: 0.0673 - acc: 0.9787 - f1: 0.9743 - val_loss: 0.6196 - val_acc: 0.7387 - val_f1: 0.7137\n",
            "Epoch 6/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.0576 - acc: 0.9796 - f1: 0.9742 - val_loss: 0.6357 - val_acc: 0.7577 - val_f1: 0.7252\n",
            "Epoch 7/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.0521 - acc: 0.9816 - f1: 0.9777 - val_loss: 0.6504 - val_acc: 0.7426 - val_f1: 0.7152\n",
            "Epoch 8/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.0467 - acc: 0.9814 - f1: 0.9773 - val_loss: 0.6843 - val_acc: 0.7413 - val_f1: 0.7167\n",
            "Epoch 9/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.0451 - acc: 0.9803 - f1: 0.9752 - val_loss: 0.6974 - val_acc: 0.7347 - val_f1: 0.7131\n",
            "Epoch 10/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.0430 - acc: 0.9833 - f1: 0.9798 - val_loss: 0.6983 - val_acc: 0.7426 - val_f1: 0.7175\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1d994cb3ee0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=10, validation_data = (x_val, y_val), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLMgK_03sOrY",
        "outputId": "9d18f0ab-0228-4616-c44d-9b2811f126dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 0s 6ms/step - loss: 0.6983 - acc: 0.7426 - f1: 0.7175\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6983233690261841, 0.7426132559776306, 0.7175071835517883]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_val,y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCjo6nmjsOrY"
      },
      "source": [
        ">### The F1 score on validation dataset is 0.7175"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ntE-Ky-sOrY"
      },
      "outputs": [],
      "source": [
        "val_pred = model.predict(x_val)\n",
        "\n",
        "val_sigmoid = np.where(val_pred > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ip71MGtsOrZ",
        "outputId": "1a777cf5-5c4e-41cf-efc1-448cb0d6b6a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.72      0.76       849\n",
            "           1       0.68      0.78      0.73       674\n",
            "\n",
            "    accuracy                           0.74      1523\n",
            "   macro avg       0.74      0.75      0.74      1523\n",
            "weighted avg       0.75      0.74      0.74      1523\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "matrix = metrics.classification_report(list(y_val),val_sigmoid)\n",
        "\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N-unPjMsOrZ"
      },
      "source": [
        "### PREDICTING ON PROVIDED DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx7gpD9ksOrZ",
        "outputId": "16eefa82-9dea-415b-8896-9a203b728b7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location  \\\n",
              "0         0     NaN      NaN   \n",
              "1         2     NaN      NaN   \n",
              "2         3     NaN      NaN   \n",
              "3         9     NaN      NaN   \n",
              "4        11     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "3258  10861     NaN      NaN   \n",
              "3259  10865     NaN      NaN   \n",
              "3260  10868     NaN      NaN   \n",
              "3261  10874     NaN      NaN   \n",
              "3262  10875     NaN      NaN   \n",
              "\n",
              "                                                   text  \n",
              "0                    Just happened a terrible car crash  \n",
              "1     Heard about #earthquake is different cities, s...  \n",
              "2     there is a forest fire at spot pond, geese are...  \n",
              "3              Apocalypse lighting. #Spokane #wildfires  \n",
              "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
              "...                                                 ...  \n",
              "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
              "3259  Storm in RI worse than last hurricane. My city...  \n",
              "3260  Green Line derailment in Chicago http://t.co/U...  \n",
              "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
              "3262  #CityofCalgary has activated its Municipal Eme...  \n",
              "\n",
              "[3263 rows x 4 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text = pd.read_csv(\"./data/test.csv\")\n",
        "input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It-raBkPsOrZ"
      },
      "outputs": [],
      "source": [
        "input_text = input_text.drop(['location', 'id', 'keyword'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axCTcRYusOrZ",
        "outputId": "8fe29791-58ea-4cce-b0de-9826934fbbbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>heard about earthquake is different cities sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>there is a forest fire at spot pond geese are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apocalypse lighting spokane wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>typhoon soudelor kills  in china and taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0                 just happened a terrible car crash\n",
              "1  heard about earthquake is different cities sta...\n",
              "2  there is a forest fire at spot pond geese are ...\n",
              "3              apocalypse lighting spokane wildfires\n",
              "4        typhoon soudelor kills  in china and taiwan"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text_clean = clean(input_text)\n",
        "\n",
        "input_text_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fil_M0HsOrZ"
      },
      "outputs": [],
      "source": [
        "input_text_vectorized = text_vectorization(input_text_clean['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r5qBK9EsOra"
      },
      "outputs": [],
      "source": [
        "input_text_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    input_text_vectorized, maxlen=None, dtype='int32', padding='post',\n",
        "        truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRsCBkWQsOra"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(input_text_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmGjksX1sOra"
      },
      "outputs": [],
      "source": [
        "pred_sigmoid = np.where(preds > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRFQpKqysOra",
        "outputId": "7e20319a-6229-4ebe-aa39-fcfa815ccd59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3263, 1)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_arr = np.asarray(input_text['text'])\n",
        "\n",
        "text_arr = np.expand_dims(text_arr, axis=1)\n",
        "\n",
        "text_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzE9IyJTsOrb"
      },
      "outputs": [],
      "source": [
        "csv_output = np.concatenate((text_arr, pred_sigmoid), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ6ZVTfisOrb"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(csv_output).to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQf1SR4PsOrb"
      },
      "source": [
        "### SAVING THE MODEL TO DIRECTORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLGGA36UsOrb"
      },
      "outputs": [],
      "source": [
        "model.save('Group_11_Lab_6.keras', save_format='h5')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dab300",
      "language": "python",
      "name": "dab300"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}